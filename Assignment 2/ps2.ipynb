{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07269d9ab37a921c251915daaba4b354",
     "grade": false,
     "grade_id": "cell-9b382cf04d08a3d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem Set 2\n",
    "Applied Machine Learning (Spring 2020)<br>\n",
    "Instructor: Rahman Peimankar (abpe@mmmi.sdu.dk)\n",
    "\n",
    "Due: March 20, 11:00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3302974014344adebe45d2297c78be97",
     "grade": false,
     "grade_id": "cell-68d97a32cf9cd5e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of this assignment is to revise the learning of the topics in Lesson 4 and Lesson 5, which are Preprocessing and\n",
    "Feature Transformation and Linear Models for Regression, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9db24efdede0f2d0f7ed411d5fa5cb1",
     "grade": false,
     "grade_id": "cell-36feb6452bceb870",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: ColumnTranformer\n",
    "\n",
    "As we learnt in the lecture, there are some challenges in transforming the data in machine learning algorithms/pipelines such as:\n",
    "* It would be challenging to transform different data types.\n",
    "* How to use a proper transformation approach.\n",
    "\n",
    "As you know, it is of utmost importance to prepare data before starting any modelling. \n",
    "\n",
    "For example, missing values should be replaced, numerical value should be scaled, and categorical variables need to be one hot encoded.\n",
    "\n",
    "To transform the data in scikit-learn, there are different classes such as [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) for replacing missing values, [MinMAxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) for scaling numerical features, and [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) for encoding categorical features.\n",
    "\n",
    "As an example:\n",
    "\n",
    "``scaler = MinMaxScaler()``<br>\n",
    "``scaler.fit(train_x)``<br>\n",
    "``train_x = scaler.transform(train_x)``<br>\n",
    "\n",
    "In addition, different data transformation can be done using [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), for example:\n",
    "\n",
    "``trnsformPipeline = Pipeline(steps=[('i', SimpleImputer(strategy='median')), ('s', MinMaxScaler())])``<br>\n",
    "``train_x = trnsformPipeline.fit_transform(train_x)``<br>\n",
    "\n",
    "In machine learning projects, you usually need to perform preprocessing on different columns of your data. For example, you may perform imputation on the missing **numerical** values and to impute missing **categorical** values using the frequent values and **one hot encode** the categories. This way you need to split your dataset into numerical and categorical data and then apply the required transformation on each variable type separately. Afterwards, you should combine them again to form the entired transform dataset. \n",
    "\n",
    "**BUT**, now the ColumnTransformer can be used to do all these operation in one place for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f64b1f5f906adc77d92eea26fd39d440",
     "grade": false,
     "grade_id": "cell-c8090d5f5d191dbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Applying ColumnTransformer on the Abalone Dataset\n",
    "\n",
    "In this exercise, we use the abalone dataset. The aim is to prepare the dataset using ColumnTransformer. \n",
    "\n",
    "You can learn more about the abalone datsaset from the link below. It is already downloaded for you to use in this assignment!\n",
    "\n",
    "[Abalone Dataset](https://archive.ics.uci.edu/ml/datasets/abalone)\n",
    "\n",
    "The aim of this dataset is to the age of an abalone using different measurements.\n",
    "\n",
    "The dataset has \n",
    "\n",
    "* 4177 instances/samples,\n",
    "* 8 input variable of different types, and\n",
    "* an integer target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9cfde34d2ea3d081ceaa78ad9dc4ada",
     "grade": false,
     "grade_id": "cell-7a6ab98a52eb7c8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q1. Please read the dataset using pandas ``read_csv`` method. You should name your dataframe as ``df``. Please remember that the dataset does not have any header. So, you should set ``header`` argument in ``read_csv`` function.\n",
    "\n",
    "**Hint**: The best way to check whether you have read the dataset correctly is to check the shape of the dataframe by running ``df.shape`` which should give you the output as ``(4177, 9)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bca50844aa8ec06eca262fbd6933553d",
     "grade": false,
     "grade_id": "cell-79c51e03f9596be4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "716318100dd75e48197844aa837ed0ec",
     "grade": true,
     "grade_id": "cell-ff0beebf23d249c2",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96509911a8a8eaab50f76c8d7e7338c7",
     "grade": false,
     "grade_id": "cell-394440ca67b0a878",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q2. You should split the dataset in a way that the last column of the dataset should be removed and saved as ``y``. And the other 8 columns should be named as ``X``.\n",
    "\n",
    "**Hint**: you may use ``drop`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8fcc5ecea55ee9040004bcf155a99b",
     "grade": false,
     "grade_id": "cell-c29d4faec0d5c3a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "last_column = len(df.columns) - 1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ea46375843688aa2b12bc83f451cc0c",
     "grade": true,
     "grade_id": "cell-f16765768fce1436",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c83f5e4d3f3f3643be0c4e9fb0da6634",
     "grade": false,
     "grade_id": "cell-b8c8e7a40c76afe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q3. Now it is the time to figure out which columns are numerical (both *'float64'* and *'int64'* types) and which of categorical type either *'object'* or *'bool'*. \n",
    "\n",
    "You should name the numerical and categorical column lists `numerical_col` and `categorical_col`, respectively. \n",
    "\n",
    "**Hint**: you may use ``select_dtypes`` function on the `X` dataframe. Read more about `select_dtypes` [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "021d23a1f2e3722e933ffdad6bb82065",
     "grade": false,
     "grade_id": "cell-65c2c196c0751720",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "228feef4f3ad6b46b06a309fa9cf5d0a",
     "grade": true,
     "grade_id": "cell-d2e1064dd4d4ae7e",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba948d2a7f13dc0440d82b0da6079b73",
     "grade": false,
     "grade_id": "cell-ded95753784ffb13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q4. It is the time for applying `ColumnTransfomer`. We should just one hot encode the first column using `OneHotEncoder` and scale the numerical columns (2-8) using `MinMaxScaler`. Name the ColumnTransformer in your code as `ct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed4354c87a21c1ea7c49e019eebf6f6b",
     "grade": false,
     "grade_id": "cell-2cb32951a89ecb5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "839f806afd222043326e7c8c250c3bc5",
     "grade": true,
     "grade_id": "cell-6ac7354fec29ed90",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "100d300767047f1de85b167871e0e529",
     "grade": false,
     "grade_id": "cell-0a1ecf50c3d77264",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. kNN Imputation\n",
    "* As we discussed in the lecture, our dataset may have some missing values. \n",
    "* For example, there are no data available for some rows in the dataset, either partially or completely. \n",
    "* Data missing has different reasons such as problem in measurement and unavailibility.\n",
    "* Most of machine learning algorithms require input data as values to be able to generate proper outputs. And these missing values can prevent the algotithms to work properly.\n",
    "* The process of finding missing values in a dataset and replace them with proper values is called data imputing. \n",
    "\n",
    "### Data Imputation Using ML Model \n",
    "* As we learnt in the lecture, one way to impute data is to fit a model to predict the missing values.\n",
    "* Such a model should be created for the features/attributes in the data that have missing values.\n",
    "* As an example, kNN can be used to impute a sample by averaging the *closest* samples to it (neighbors) in the training set. \n",
    "\n",
    "### Dataset\n",
    "In this exercise, the Horse Colic Dataset is used, which includes medical features of horses with colic. The dataset is telling us whether the horses lived or died. You can read more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/Horse+Colic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "febc2d789e9ef460564e07d69556d7e2",
     "grade": false,
     "grade_id": "cell-ceee45c510897974",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "285e48ec65ce5c40e85ca830139b2b22",
     "grade": false,
     "grade_id": "cell-5a421308efe026f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q5. First, please import the dataframe and name it as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e3d21d28d3b82ee7c1f96768df38593",
     "grade": false,
     "grade_id": "cell-72fd5fd56e7f2b4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def importDF():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a2d17be1dda4c3df8bcad2231ff2e51",
     "grade": true,
     "grade_id": "cell-c579849368f2073b",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41c97ab27550a8a6ee704a00df8aa254",
     "grade": false,
     "grade_id": "cell-d88676af408e15ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you look into the dataframe by using `importDF().head()`, you can see that the missing values are marked as `?`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "243807a2092cf2089451bca4994a727a",
     "grade": false,
     "grade_id": "cell-29d60e04f01b1064",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q6. Now you should replace these `?` with `NaN`. \n",
    "\n",
    "**Hint**: one way to do this can be by passing `na_values` in the `read_csv` function when reading the dataset. Please read more about `na_values` on this [page](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "551c18726fba942bfd06b53621722a92",
     "grade": false,
     "grade_id": "cell-b96052b71cba9284",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def replaceMissingValues():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5439ae2f5f9b9d9f0cadfeb1f446b585",
     "grade": true,
     "grade_id": "cell-42149d236619d0b8",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0766faf22ff0d9214192a39100fb481",
     "grade": false,
     "grade_id": "cell-40c1cbb5fd59cc26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the cell below to check if the missing values have been replaced with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7b0b57923817248f0e9d35461478fb4",
     "grade": false,
     "grade_id": "cell-44a4220354dcf9f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "replaceMissingValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fbc186ae7d06dc533724fb849bbd183",
     "grade": false,
     "grade_id": "cell-925b69cc7ae7952a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q7. Complete the code below to report the number rows with missing values for each column.\n",
    "\n",
    "**Hint**: You may use `.isnull()` function in pandas and then count the number of missing values for each column in the for loop below using `.sum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d6cccb4f99ce2607b3f65b4e6713eb8",
     "grade": false,
     "grade_id": "cell-9200535fbedd6da5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = replaceMissingValues()\n",
    "for col in range(df.shape[1]):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print('Column {} has {} missing values.'.format(col, n_miss.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54595a1f13c854c8b9bcb5944faa125b",
     "grade": true,
     "grade_id": "cell-3d634dbac555e818",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8c3e966ef2327919bfe5bbd4004b5b5",
     "grade": false,
     "grade_id": "cell-41bc58f02a503a67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it is time to use `KNNImputer` from `sklearn` to implement the kNN imputation. You can read more about `KNNImputer` in [this link](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8eb4bf3c2914bb48f6ed472ecdc0f4c",
     "grade": false,
     "grade_id": "cell-3325bd0055e1561e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q8. Create an imputer object using `KNNImputer` such that `n_neighbors=5`, `weights='uniform'`, and `metric='nan_euclidean'`. Read more about theese parameters in the link above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb5957ed4e2ba443eda0435e87209010",
     "grade": false,
     "grade_id": "cell-144097d5398b0a3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "906ebd82f5569c42a62c94bc07d7ac5e",
     "grade": true,
     "grade_id": "cell-6e886d172b6d1885",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def knnImputer():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be9a7475d3f0f60172e975c3b5bbf0ad",
     "grade": false,
     "grade_id": "cell-50ef36d52a1b17fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should now be able to apply `.fit()` function on your created `imputer` object above. To do this, you should prepare the input data for the `.fit()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5aa4a1a1a4931d65edf03f787813895a",
     "grade": false,
     "grade_id": "cell-57214e76a69ce805",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q9. Complete the code below to first split input features ($X$) and labels/ouputs ($y$). Then, you can use $X$ to apply `.fit()` function on `imputer` object. \n",
    "\n",
    "**Hint**: Column 23 should be considered as output ($y$). Please check the datset description file (*horse-colic-names.txt*). \n",
    "\n",
    "**Attention**: The operation in line 4 (cell below) is called *list comprehensions* in Python. List comprehensions is nothing but an wapproach in Python programming to build a list from a for loop all in one place. You can read more about it [here](https://jakevdp.github.io/WhirlwindTourOfPython/11-list-comprehensions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1898d852b401a7098322dabcfb25f1d",
     "grade": false,
     "grade_id": "cell-8a494007f1c64cf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def splitData():\n",
    "    df = replaceMissingValues() \n",
    "    data = df.values\n",
    "    idx = [col for col in range(data.shape[1]) if col != 23]\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "347d4e415ee3744be2bac2aad34f1c10",
     "grade": true,
     "grade_id": "cell-dfbc6755e4002740",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eed31b081bdf269595ff24e6019606bb",
     "grade": false,
     "grade_id": "cell-20b7ab6a73af67f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q10. Return a fitted `imputer` object in the function below using training set `X` using `.fit()` function. Then, transform the training set (`X`) by applying `transform` function. Name the transformed data as `Xtransformed` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31dd471cc949a9bd688b2d223f7ccb74",
     "grade": false,
     "grade_id": "cell-931b3a2aa5610639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fitImputer():\n",
    "    imputer= knnImputer()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6136f5da6054667fad600d94eafc5ee",
     "grade": true,
     "grade_id": "cell-dc91a7cdb8cf12c2",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4384b693aedb8b11a4d8d84cd833fc8",
     "grade": false,
     "grade_id": "cell-ef795677193f194c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Hint**: If you would like to test your implementation, you can run the cell below and it should print zero as number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81b423158fea98a4f72a6732517f3d66",
     "grade": false,
     "grade_id": "cell-631051f9e55fdd40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import isnan\n",
    "print('Number of missing values: %d' % sum(isnan(fitImputer()).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e25fdc4e0a0b02fb2591f1a64e043894",
     "grade": false,
     "grade_id": "cell-50cdefe0afe79dc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Linear Regression\n",
    "\n",
    "In this exercise, we will practice a step by step process for the implementation of Linear Regression with `sklearn`. As you learnt in the lecture, the goal of regression problems is to estimate continuos values as targets. Linear regression is a way to model the linear relationship between input features and target variables. \n",
    "\n",
    "In this exercise we use the [California Housing Prices](https://www.kaggle.com/camnugent/california-housing-prices) dataset. The dataset has been put in the same folder as the assignment for you to use.\n",
    "\n",
    "You will apply Linear Regression and ColumnTransformer using a `sklearn` pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "131e128ff685d5be89a8f57e67b4c0ca",
     "grade": false,
     "grade_id": "cell-9b08a856c755b092",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q11. Please import the dataset using pandas and name it as `df_housing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05ce314ddd3be8f14895da80d84d264f",
     "grade": false,
     "grade_id": "cell-43e1087eb68d2e6c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d82e1b494903c2c548dc9007b70c96be",
     "grade": true,
     "grade_id": "cell-46409ee6fe0f85ee",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b58ad5cce8f8c30a37650e4abae9c046",
     "grade": false,
     "grade_id": "cell-14f15dfa02e6b9ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Hint**: There are some missing values with `total_bedrooms` feature as you can see in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1db9a99b8b329f1207ea523b9a3e206b",
     "grade": false,
     "grade_id": "cell-e360ca24421893a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_housing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81f6b3f2bc29fde2c63f5aa1ff84be3",
     "grade": false,
     "grade_id": "cell-aa4620ef9267e09b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q12. Substitute the missing values using `median` of the `total_bedrooms`. A copy of the original datframe has been created inside the function `df_filled` so that you can use it in your implementation. \n",
    "\n",
    "**Hint**: You may set `inplace=True` using the `.fillna()` function. Read more about it [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16387e9e5fe554021eb050bdb3937ab3",
     "grade": false,
     "grade_id": "cell-67c9da841c6780b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def missingMedian(df_housing):\n",
    "    df_filled = df_housing.copy()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ed6446e721d34aae7618e40587ff14",
     "grade": true,
     "grade_id": "cell-66af3c01d14d1043",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38b108a5c7272d5f08dcd65b52560b6e",
     "grade": false,
     "grade_id": "cell-6c4f6a54fe4960ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it is time to use ColumnTransformer and Pipeline on our dataset!\n",
    "\n",
    "First, we divide numeric and categorical columns of our dataset. There is only one categorical feature, which is `ocean_proximity`. The rest are numeric features. Look at the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d54f6c6498715ec8ec4b86f2d1ef62b5",
     "grade": false,
     "grade_id": "cell-8df154b5d8afee55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "missingMedian(df_housing).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fae281a20a05865c5bbeb1834621265",
     "grade": false,
     "grade_id": "cell-f7094af3404ee4de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We make two pipelines for both numeric and categorical columns. Name the two numeric and categorical pipelines as `numPipe` and `catPipe`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Fisrt make the numeric pipeline (`numPipe`) and apply `PolynomialFeatures` and `StandardScaler`.\n",
    "\n",
    "**Important**: The degree of polynomial should be set to two (`degree=2`) and the parameters of `StandardScaler` should be left as default. And you should name the steps of the Pipeline as `poly` and `scaler` for `PolynomialFeatures` and `StandardScaler`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68df02556b8c0fb1f579cf12f324cfc9",
     "grade": true,
     "grade_id": "cell-4393581a8f994cbe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62c58a6db2e8efc012bdfbc107e87927",
     "grade": false,
     "grade_id": "cell-4323b9c5b01f84c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q13. Now make the categorical pipeline (`catPipe`) and apply `OneHotEncoder`. And you should name the step of the Pipeline as `onehot`. \n",
    "\n",
    "**Important**: Set the `handle_unknown='ignore'` for `OneHotEncoder`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63106f9b966213719a222655fc895827",
     "grade": true,
     "grade_id": "cell-3bf8595da62d3e90",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17776d61d04df4c9b86dc55cb7d0de40",
     "grade": false,
     "grade_id": "cell-26af10ef48eb8a3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q14. You have preprocessd both numeric and categorical features. So, combine them using `ColumnTransformer`. Name the `ColumnTransformer` as `colTrans`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86c5785a5dc78e6aac8786f6d78db130",
     "grade": false,
     "grade_id": "cell-cb3bd95e819c75fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Hint**: The cells below divide the numeric and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "715850626fcdf1a1448733003be11927",
     "grade": false,
     "grade_id": "cell-2cc55bdaf511a8f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "numFeat = ['longitude','latitude','housing_median_age', 'total_rooms','total_bedrooms', 'population',\n",
    "           'households','median_income']\n",
    "catFeat = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3331960b621d04dfe2f52f95b037e630",
     "grade": true,
     "grade_id": "cell-ecde732d9f6760d7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d58ce6359c1cfa97b2d7d8c0c6ecef6a",
     "grade": false,
     "grade_id": "cell-9a154fe592e5b735",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So far you have created completed the preprocessing step and you have a `ColumnTransformer` called `colTrans`. This is a very good news! \n",
    "\n",
    "Now, you can make another Pipeline to integrate `LinearRegression` model and the `ColumnTransformer`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64ed88e57611ff032be3de2a4245d1d5",
     "grade": false,
     "grade_id": "cell-3c4f352c4c7331ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr_pipe = Pipeline(steps=[('preprocessing', colTrans),\n",
    "                      ('classifier', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4faf9b18716b2d27c00a9f5763f88b41",
     "grade": false,
     "grade_id": "cell-72afbe289a5626e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We are now ready to start the fun part! We can train our LinearRegression model. However, first we need to split inputs and target and name them as `X` and `y`.\n",
    "\n",
    "**Hint**: You may use `df_filled` dataframe, which is the output of `missingMedian(df_housing)` function. The target (`y`) is the *median_house_value* column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1120af6eff10e0c4206c9a6d8012a4d2",
     "grade": false,
     "grade_id": "cell-b9fe070c7acee52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q15. Define inputs and target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e5fda3032954caf42dacfe7e6779980",
     "grade": false,
     "grade_id": "cell-75727988cd42e6af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_filled = missingMedian(df_housing)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f96c399d67eb8023fd26d5f33e211381",
     "grade": true,
     "grade_id": "cell-b8113be9f8915244",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f75a1a9f75b9077f814ff0932c6e1723",
     "grade": false,
     "grade_id": "cell-c2703a62cb38ace7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q16. Split the inputs and target into train and test sets using `train_test_split`. You should set the `random_state = 42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50127a4ba4b732163c235f58f41dc985",
     "grade": false,
     "grade_id": "cell-3f56abc1f5d40d28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def splitData(X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34d17c3af575d1d96e22c47f8125b1dc",
     "grade": true,
     "grade_id": "cell-2bf0a8cad6a999f7",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06e41888821e0b011dd9f787709ef9ad",
     "grade": false,
     "grade_id": "cell-b71dc5f4fc2e9b07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q17. Train the Linear Regression model using `X_train` and `y_train` by applying `.fit()` function on the created Pipeline `lr_pipe`.\n",
    "\n",
    "Then, evaluate the model using `.score()` function on both train and test sets.\n",
    "\n",
    "**Hint**: The performance of your model on the train and test sets should be around 75% and 67%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "120efca3479122099bfca0df1caa72db",
     "grade": true,
     "grade_id": "cell-ac12d23fdcb2a6ef",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
