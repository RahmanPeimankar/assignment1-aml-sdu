{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ad52a90ef51854c3d3984ff1cf7d6bc",
     "grade": false,
     "grade_id": "cell-b21e3d3d498993ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem Set 3\n",
    "Applied Machine Learning (Spring 2020)<br>\n",
    "Instructor: Rahman Peimankar (abpe@mmmi.sdu.dk)\n",
    "\n",
    "Due: April 23, 11:00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79ce30901b64a2fce9313d7c937634ef",
     "grade": false,
     "grade_id": "cell-a83fdce2e29380e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of this assignment is to revise the learning of *Non-linear Models*, *Model Evaluation*, *Dimensionalty Reduction*, and *Neural Networks*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b936457fcb20766975ec8a1c6d61f5ce",
     "grade": false,
     "grade_id": "cell-bd7a7ffc25d479ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Random Forests\n",
    "\n",
    "As we learnt in the lecture, random forests is an ensemble of decision trees that is built using bootstarped datasets and only a subset of features in each step of single trees. \n",
    "\n",
    "Then, the outputs of all of the trees will be aggregated to make a final decision on each sample. This process of using **bootstraped** data and **aggregating** of single trees outpts is called **bagging**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "165edbb7d35e4134e021968915f515eb",
     "grade": false,
     "grade_id": "cell-95ed7ba464a66420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Preparing the data\n",
    "\n",
    "In this exercise, we use the wine dataset to predict wine quality. \n",
    "\n",
    "You can learn more about the wine datsaset from the link below. It is already downloaded for you to use in this assignment!\n",
    "\n",
    "[Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "\n",
    "The dataset has \n",
    "\n",
    "* 1599 instances/samples, and\n",
    "* 12 input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "355e30500c37d49dd8f26bd4c886e47b",
     "grade": false,
     "grade_id": "cell-e791a5cee053055f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q1. Please read the dataset using pandas ``read_csv`` method. You should name your dataframe as ``df``. \n",
    "\n",
    "**Hint**: The best way to check whether you have read the dataset correctly is to check the shape of the dataframe by running ``df.shape`` which should give you the output as ``(1599, 12)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3da4f16c1f8d91af9cc50c34458db03",
     "grade": false,
     "grade_id": "cell-0f0dcd9915ca1130",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdbc017b52b06fc9e9fc14bc0c00feb1",
     "grade": true,
     "grade_id": "cell-0ae79975510a7831",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a4a9f24413f6aab970400bcae41aab8",
     "grade": false,
     "grade_id": "cell-7d28e8f01b3e85f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a39da8675b94547270e34de435fe6fe",
     "grade": false,
     "grade_id": "cell-5976a4e9d170c98f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93eac8cb6ee8c1494d32ecdf08a834bd",
     "grade": false,
     "grade_id": "cell-a6a18278894748f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q2. Now that you have imported the dataset as a dataframe, you can split the features and targets/label as ``X`` and ``y``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4e7fd4d123aa596c48fe92871c7a5c9",
     "grade": false,
     "grade_id": "cell-7686053d9b19f0ea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1282586c95f2e6d6bc27faaaed35b383",
     "grade": true,
     "grade_id": "cell-83f8779ff0cdc4b8",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f2ababbdefa91e8eb8a501064fe299b",
     "grade": false,
     "grade_id": "cell-a2b2459816a8fe5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q3. Next, you should create a random forests regressor using *scikit-learn ensemble* module. Name the random forests regressor as *rf_reg*. Set ``random_state=42``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87a1ac3b338870fb8dbfe1de73fa49ca",
     "grade": false,
     "grade_id": "cell-b91d9eaf8d8721ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "220f17d50967910b485217bc3dd836fa",
     "grade": true,
     "grade_id": "cell-bcab2f634288a38f",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7fd0ee580e2ccbae0f0afb895fbfefe",
     "grade": false,
     "grade_id": "cell-e216ff9388c5e16e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Hint**: You should get the same results for your *rf_reg* estimator as in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a17f501f220ef338d8493e6a9010e2f",
     "grade": false,
     "grade_id": "cell-7ac124695015ab07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)\n",
    "rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc0479648e3bb7b409311ec295fc7938",
     "grade": false,
     "grade_id": "cell-ff0c857d8eaba3c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q4. One of the important parameters of random forests is ``n_estimators``, which is actually the number of trees that should grow. So, let's tune this parameter. Please complete the code below to search and find the optimum number of trees.\n",
    "\n",
    "**Hint**: As we learnt in the lecture, the number of trees should be large enough to stabilize the error of the random forests model. So, we evaluate each ``n_estimators`` value in the for loop using *5-fold cross validation*. You should use a ``cross_val_score`` for this purpose and name the output of this function ``mse_scores``. Also set ``scoring='neg_mean_squared_error'`` , ``n_jobs=-1``, and ``cv=5`` in the ``cross_val_score`` function.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "**Hint**: Please remember that parameters tuning step should be done using train data (``X_train`` and ``y_train``).\n",
    "\n",
    "**Note**: It may take a while to run the code below, please be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99e073bf4374f39e8fd53e132aea4850",
     "grade": true,
     "grade_id": "cell-1f9ff0eb45fc610c",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "estimator_range = range(10, 310, 10)\n",
    "\n",
    "rmse_scores = []\n",
    "\n",
    "for estimator in estimator_range:\n",
    "    rf_reg = RandomForestRegressor(n_estimators=estimator, random_state=42)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    rmse_scores.append(np.mean(np.sqrt(-mse_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1768a7816ee1a623c35c5c083691226f",
     "grade": false,
     "grade_id": "cell-b29cd68e1ab8c331",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q5. Wouldn't be a good idea to plot the ``rmse_scores`` (y-axis) versus ``n_estimators`` (x-axis) to see what is going on here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87531d92fa6ddaae2f917fd9a1ceafea",
     "grade": true,
     "grade_id": "cell-f559d973740d92e7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8a2db145dc2b07bc6d110429c3d079c",
     "grade": false,
     "grade_id": "cell-815ec3ba318596ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q6. Now, find the minimum value of RMSE and its corresponding number of estimators. Name the lowest error value and its number of estimators as ``err`` and ``num_est``, respectively. \n",
    "\n",
    "**Hint**: One solution would be to first zip ``rmse_scores``and ``estimator_range`` and then apply ``sorted`` function. Then, you can return the first index ``[0]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "234c12c66d12b35e7d639f915b746079",
     "grade": false,
     "grade_id": "cell-5c4b0191f3dff55a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Minimum error is {} and its corresponding number of estimators is {}.'.format(err, num_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34772eb342f3fe106052446d0204e806",
     "grade": true,
     "grade_id": "cell-c72271c59cdf2256",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec1a4a140fe5277ea2dd39505a3f84d6",
     "grade": false,
     "grade_id": "cell-261d0e82a1f10586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q7. Another important parameter that we need to optimize is ``max_feature``, which is the number features used in each step to create the trees. So, please complete the code below to find the best value similar to above example for ``n_estimator``.\n",
    "\n",
    "**Hint**: Please pay attention that the ``n_estimator=num_est``, which is the optimum number of estimators found in the previous step. Also as in the previous question, you should use a ``cross_val_score`` and name the output of this function ``mse_scores_feat``. Also set ``scoring='neg_mean_squared_error'``, ``n_jobs=-1``, and ``cv=5`` in the ``cross_val_score`` function.\n",
    "\n",
    "**Note**: It may take a while to run the code below, please be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a17fda834313320da3ee18a60155b1f",
     "grade": true,
     "grade_id": "cell-451d2468fe02e871",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "feature_range = range(1, df.shape[1])\n",
    "rmse_scores_feat = []\n",
    "\n",
    "for feature in feature_range:\n",
    "    rf_reg = RandomForestRegressor(n_estimators=num_est, max_features=feature, random_state=42)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    rmse_scores_feat.append(np.mean(np.sqrt(-mse_scores_feat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "893dc771e4d9ed1f2c0a17a7e2d61328",
     "grade": false,
     "grade_id": "cell-dd19b3468920425f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q8. Again, it would be a good idea to plot the ``rmse_scores_feat`` (y-axis) versus ``max_features`` (x-axis) to see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9837f98f417921960e2003da8fc348",
     "grade": true,
     "grade_id": "cell-95b083d390f48cf9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "232d1ef4c5aad954fac44e80d44c5a3c",
     "grade": false,
     "grade_id": "cell-9b509c1fe0d57711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q9. Now, find the minimum value of RMSE and its corresponding maximum number of features. Name the lowest error value and its number of estimators as ``err_feat`` and ``max_feat``, respectively. \n",
    "\n",
    "**Hint**: One solution would be to first zip ``rmse_scores_feat``and ``feature_range`` and then apply ``sorted`` function. Then, you can return the first index ``[0]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6b58ed16e260a3ffee3097759759ac6",
     "grade": false,
     "grade_id": "cell-20e3381ccbe97ec4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Minimum error is {} and its corresponding maximum number of features is {}.'.format(err_feat, max_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6551dd1d36f4ee084e5f99dd6ee2b1e",
     "grade": true,
     "grade_id": "cell-0a2fd5a6f2a17b65",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "222d0a308787b02fd34b8849c982b57f",
     "grade": false,
     "grade_id": "cell-414687507bb21d04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q10. So far, we have found the optimum parameters for ``n_estimators`` and ``max_features``. Thus, we can train our random forest regression using these parameters. Please train the model using these optimum parameters and return the train and test scores using ``.score()`` function and name them ``train_score`` and ``test_score``, respectively.\n",
    "\n",
    "**Note**: As in the previous steps, you should set ``random_state=42``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95e7441e2e70ecd6b1d68eca68ce8f0b",
     "grade": false,
     "grade_id": "cell-fcce12d7bc463e86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2882c57366eebb30d02b0ba435883f1c",
     "grade": true,
     "grade_id": "cell-a984d2617c27d7b4",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "690e435f644b6a49365dadb59bced4ef",
     "grade": false,
     "grade_id": "cell-74d78ddbdb2d89fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q11. As we discussed in the lessons, random forests are capable of identifying the important features. So, please complete the code below to return the weights of the feature importance. Please name the output variables as ``feat_imp``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ef465937cabdafdcdc9923b8252aba",
     "grade": false,
     "grade_id": "cell-48c05d49c47ca278",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "feat_imp.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca09a48decebd50b88edf9a95d2be79e",
     "grade": true,
     "grade_id": "cell-bcd71596ce1ebf2a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "790eb61dd1d0734fee4933474a0c62fe",
     "grade": false,
     "grade_id": "cell-69a86825b7137c8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot the feture importance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba36003bf7bd9d6c03c726f2a8ed3ae9",
     "grade": false,
     "grade_id": "cell-3e633ae32584f8de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.barh(range(11), np.sort(rf_reg.feature_importances_[0:11]))\n",
    "plt.yticks(range(11), df.columns.tolist()[0:11])\n",
    "plt.tick_params(axis='x', labelsize=20)\n",
    "plt.tick_params(axis='y', labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6502b8e16f755212f29e09ec85816247",
     "grade": false,
     "grade_id": "cell-a7e608513b24276c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: So, *alcohol*, *sulphates*, and *volatile acidity* are the three most important features. So, one can only use these three feature to train the random forests to decrease the computational time and achieve the performance as close as possible to using all the features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57cd165b3d32ed92c32ea93d42121e7e",
     "grade": false,
     "grade_id": "cell-6308f33f4ccff542",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Model Evaluation\n",
    "In the lecture, we reviewed some of the very well-known techniques for classification models such as Confusion Matrix, ROC Graph, Sensitivity and Specificity. Also, we learnt about ``classification_report`` funcion in scikit-learn.\n",
    "\n",
    "In this section, we would like to apply these metrics to evaluate how good the following classifier performs on the *dibetes.csv* dataset that has been already downloaded into this folder for us to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92224a44251d25d6405b1c1762c607a6",
     "grade": false,
     "grade_id": "cell-5988888514b5b147",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "df_diabetes = pd.read_csv('diabetes.csv', header=0, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9047c02be9775992c6dc1829a7ba5bd1",
     "grade": false,
     "grade_id": "cell-8f24d47b0518616a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_diabetes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f464a3a36389a18a83527fd587222cf",
     "grade": false,
     "grade_id": "cell-ca490885e8ce424b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df_diabetes.loc[:, df_diabetes.columns != 'label']\n",
    "y = df_diabetes.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "svm_clf = SVC(probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = svm_clf.predict(X_train)\n",
    "y_pred_test = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd53c0ea8b386b161287785d1d557e9f",
     "grade": false,
     "grade_id": "cell-f1fcd02fda1cfbf7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q12. Please use ``accuracy_score`` function to report the accuracy on train and test data name them as ``train_acc`` and ``test_acc``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b24a0b21a05bd69a84294d0a9d873687",
     "grade": false,
     "grade_id": "cell-9e89021a76d40c1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Train accuracy:{}'.format(train_acc))\n",
    "print('Test accuracy:{}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f78ce8fd3d576d4c5a86e61a80657853",
     "grade": true,
     "grade_id": "cell-8897a07758ac9857",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4575bc76882ede5347adfea338cc07ba",
     "grade": false,
     "grade_id": "cell-73e08b6e48e87621",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Classification accuracy is the easiest metric to use. But it does not tell you what types of errors you model is making. In other words, it does not tell how your classifier performs on each class! Thus, let's look at other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b753679949799739eab30e62fcc6580d",
     "grade": false,
     "grade_id": "cell-a5ca1431d27de6cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q13. Use ``confusion_matrix`` function from ``metrics`` class to calculate the confusion matrix on both train and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3843221eb1655543f860dc29b6c97863",
     "grade": false,
     "grade_id": "cell-6441e89b74448f6b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('Train confusion matrix:{}'.format(cm_train))\n",
    "print('Test confusion matrix:{}'.format(cm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c265e2801fb3014b224ca5f2ca3a8066",
     "grade": true,
     "grade_id": "cell-f8816eac17f7d418",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1ea6cf195dbf32d3197cbdbd3dff042",
     "grade": false,
     "grade_id": "cell-8d43fbe957ebf2f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q14. Now, use ``plot_confusion_matrix`` to plot the confusion matrix for both train and test data. Please set ``cmap=plt.cm.Blues`` to get a better looking confusion matrix. You may learn more about ``plot_confusion_matrix``here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88d318d20bd8a59d467cbb38c72cdfcc",
     "grade": true,
     "grade_id": "cell-a8bc871ab06cea32",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7556364130536f8a2a1ab5e374b11ed6",
     "grade": false,
     "grade_id": "cell-69f843af92691658",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can get the *True Positives*, *False positives*, *False Negatives*, and *True Positives* as the output of ``confusion_matrix`` function as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f09760c02835bb39c43da39aed6ad8cf",
     "grade": false,
     "grade_id": "cell-42aa227f6bf531b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tn_test, fp_test, fn_test, tp_test = metrics.confusion_matrix(y_test, y_pred_test).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c607e08f74421ab87fc7f5c9c18d0ec2",
     "grade": false,
     "grade_id": "cell-e3d6bb146c2f93df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q15. Please calculate *Sensitivity*, *Specificity*, and *Precision* for only test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa1f5e48672a0338f4b49b6376797dad",
     "grade": false,
     "grade_id": "cell-c337c383314d133d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a93434a1ad1ab6185a5fe767e7c78232",
     "grade": true,
     "grade_id": "cell-4550ba0d611f2770",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98fde9c3f122fdd49a4f26a37d47274c",
     "grade": false,
     "grade_id": "cell-8fa99f78bf02f40f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q16. It would be nice to plot the ROC graph to see how sensitivity and specificity are affected by various thresholds. So, you will complete the code below to presents the ROC curve on the test set using ``roc_curve`` function from ``metrics`` class.\n",
    "\n",
    "**Note**: To be able to plot ROC, we need to first compute the probability outputs for each samples in the dataset using ``predict_proba`` function available from scikit-learn API and we get the second column as the probabilities as in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c2726e5a8e3e6f780b0bdad1e1537bf",
     "grade": true,
     "grade_id": "cell-7648cbd9830edb65",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob_test = svm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for SVM classifier on the test set')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09f484dc6588ad6268dc21259fe530c3",
     "grade": false,
     "grade_id": "cell-919447a21ce05cea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q17. Lastly, it would be very nice to report Compute Area Under the Curve (AUC) using ``auc`` from ``metrics`` class and name it ``auc_test``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cda3a35b5e56b7f84353bd65adbc3fe2",
     "grade": false,
     "grade_id": "cell-b19bf2c64373f05e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "843bc159aab038aca0ebcccc904d7b52",
     "grade": true,
     "grade_id": "cell-b35da567610183e9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e134c2b093dcadd56c706b7d8bd551a",
     "grade": false,
     "grade_id": "cell-586eef5b628707fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 3: Dimensionality Reduction & Clustering\n",
    "In this section, we would like to combine PCA with K-means clustering. This way, you can improve the performance of the K-means clustering algorithm. There are different reasons for using PCA before apply K-means clustering and why this improves the performance of the clustering. First, the number of features can be reduced, which results in a better performance of the algorithm. Second, reducing the number of features will help reducing the noise and consequently a better performance. If you are interested in learning more about the theory of the relationship between PCA and K-means clustering, you may find this paper interesting:\n",
    "\n",
    "http://ranger.uta.edu/~chqding/papers/KmeansPCA1.pdf\n",
    "\n",
    "In the following, we will see the effect of using PCA for clustering the *iris* dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356328fe74e7e0c14ca6ab3b95c4ca2",
     "grade": false,
     "grade_id": "cell-94925eb6c386b630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's import the required packages and load the *iris* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "161ee5263c500883ff19e5f98eb42095",
     "grade": false,
     "grade_id": "cell-5c959c536f8339d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e388d6bde6ad24b3443e421e7b19253",
     "grade": false,
     "grade_id": "cell-a361420ca48bfad1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It would be nice to plot the datset using only two arbitrary predictors (e.g. *Sepal Width* and *Sepal Length*). The color coding shows the three different groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84798149ab075e266ee5fcc6480d85da",
     "grade": false,
     "grade_id": "cell-53c11760d2d977ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='nipy_spectral')\n",
    "plt.xlabel('speal length')\n",
    "plt.ylabel('sepal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7d64b31cd3c3f5661a23d46d159c920",
     "grade": false,
     "grade_id": "cell-4734d02a9adf6235",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q18. In this part, you will complete the code below to implement a K-means clustering algorithm without PCA. Please fit ``KMeans`` function from ``sklearn.cluster`` to the ``X_train`` data. Please name the K-means estimator as ``kMeans``.\n",
    "\n",
    "**Hint**: You should set ``n_clusters = 3`` and ``random_state=42``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b60251518e3819e9bc032195072fbc5",
     "grade": false,
     "grade_id": "cell-af7db151453eaabc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "kMeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d3b1b6d2b814b85367219f064ce8d2d",
     "grade": true,
     "grade_id": "cell-e26c328b62529ac2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efad0a323fabf1773a17200827365927",
     "grade": false,
     "grade_id": "cell-32e844db05117c40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: We can measure how good our K-means clustering algorithm performs by using ``mutual_info_score`` function, which measures the similarity between two labels of the same data for two clusterings. For more information about ``mutual_info_score`` function: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score\n",
    "\n",
    "To learn more about available metrics in scikit-learn API for clastering, classification, and regression models, please take a look here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b15642d20a52cf23024487bfa9682596",
     "grade": false,
     "grade_id": "cell-e3b1a9507b2f75bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "new_predicted_clusters = kMeans.labels_\n",
    "mutual_info_score(y, new_predicted_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d02b850e57cd385d9f3e57233ffc9ad3",
     "grade": false,
     "grade_id": "cell-af25a44bd8b66fd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q19. Now, we would like to transform the input features and reduce the dimensionality using ``PCA`` function to see whether the performance is improved or not. So, you should complete the code below to create a ``PCA`` estimator (name it ``pca``) with, and, then apply ``KMeans`` as clustring model on the ``X_transformed`` data. \n",
    "\n",
    "**Hint**: You should apply first ``.fit()`` function to the ``pca`` estimator on the ``X`` data (input features). Then, transform the ``X`` data using the ``pca`` estimator using ``.transform()`` function (name the transformed data as ``X_transformed``).\n",
    "\n",
    "**Note**: Please set the ``n_components=1`` and ``random_state=42`` for the ``PCA`` function. Also, implement the ``KMeans`` same as in Q18 with the same parameters (``n_clusters = 3`` and ``random_state=42``).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dc6c5c0c28daf74189068e98b74db11",
     "grade": false,
     "grade_id": "cell-16fc6d3b0231695d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "kMeans.fit(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22d471e606e1a361869f0fdc449ad6ec",
     "grade": true,
     "grade_id": "cell-6fa58df535033441",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eed3f67bb226404f17d7dc746115b4cc",
     "grade": false,
     "grade_id": "cell-354169809161e449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check if the ``PCA`` step has improved our K-means clustering using the same ``mutual_info_score`` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e76e0fa485c8f4c174f1e53a6216b84",
     "grade": false,
     "grade_id": "cell-25d95cef13088fab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "new_predicted_clusters_pca = kMeans.labels_\n",
    "mutual_info_score(y, new_predicted_clusters_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74404e1c026dccaa10600773bda4386a",
     "grade": false,
     "grade_id": "cell-df24e7efd078883f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see the ``mutual_info_score`` measure has been improved around 4%, which is pretty good result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d04440a370b29807b3b73936e48104b9",
     "grade": false,
     "grade_id": "cell-64f704dd80c1f4de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 4: Neural Networks\n",
    "In this part, we will practice together on how to implement Neural Networks (NNs) in Keras.\n",
    "\n",
    "We are going to use the *diabetes* dataset as used in Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d493628663a62dfed578e6096b547a21",
     "grade": false,
     "grade_id": "cell-5d2e963b4350aab9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "df_diabetes = pd.read_csv('diabetes.csv', header=0, names=col_names)\n",
    "\n",
    "X = df_diabetes.loc[:, df_diabetes.columns != 'label']\n",
    "y = df_diabetes.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fa7e62543cf9881af48cac7cbf0bca2",
     "grade": false,
     "grade_id": "cell-8fbfbfe779d4262e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, you need to install Keras with Tensorflow backend, if you have not already installed it.\n",
    "\n",
    "You may install Keras using *Anaconda Prompt* and this command: ``conda install -c conda-forge keras``.\n",
    "\n",
    "https://anaconda.org/conda-forge/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4e7701a5a2cd21b1d16bcf52cfa6b31",
     "grade": false,
     "grade_id": "cell-0c6b25cb4837fda3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q20. Define a ``Sequential`` model in keras, which has three ``Dense`` layers and ``20``, ``10``, and ``1`` hidden neurons, respectively. \n",
    "\n",
    "**Hint**: You should specify the ``input_dim`` for the first ``Dense`` layer and assign ``relu`` activation function for the first two layers and ``sigmoid`` activation for the last layer. You should also set ``init='uniform'`` in all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bfa178fc690ee85ce93f39cfe8aff01",
     "grade": true,
     "grade_id": "cell-bf7157fd97b50683",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = keras.Sequential()\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c9fc67458f99fa843f6d86fac9339d2",
     "grade": false,
     "grade_id": "cell-e9426138c8886a88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q21. Now it is time to compile our model using ``compile`` function. Please use ``'binary_crossentropy'`` loss, ``'adam'`` optimizer, and ``'accuracy'`` as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2dddf39e529695b59a59c3f95e03b398",
     "grade": true,
     "grade_id": "cell-1992ec32bca6cb77",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bf82a8e10a44d2673c71a5a144f52f6",
     "grade": false,
     "grade_id": "cell-f82392c71973be8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q22. Let's fit the ``X_train`` and ``y_tarin`` data to the model.\n",
    "\n",
    "**Hint**: You should set ``validation_split=0.2``, ``epochs=200``, and ``batch_size=10``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ecbfb1dea728ec8e7e72b3a87b05c00",
     "grade": true,
     "grade_id": "cell-d7a8af30fbe7e0a9",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38ed12735dbae969c3d065d11eb7f697",
     "grade": false,
     "grade_id": "cell-d9801e563c8ef254",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q23. It is time to evaluate the model on botd train and test sets (``X_train`` and ``X_test``). Please use ``evaluate`` function to return train and test accuracy and name them ``score_tr`` and ``score_ts``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c16411aec721840908e791006faecd4d",
     "grade": false,
     "grade_id": "cell-4e90d46f01d4bdc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Training accuracy is: {}\".format(score_tr[1]))\n",
    "print(\"Test accuracy is: {}\".format(score_ts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6613f805bafaed6f996efbd35b7579c",
     "grade": true,
     "grade_id": "cell-38bf9d2546770951",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f33e147d5e1e6e12791dc335b499493",
     "grade": false,
     "grade_id": "cell-9e80d7d2c40d769f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# End of PS3.\n",
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
